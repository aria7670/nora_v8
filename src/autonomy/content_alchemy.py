
"""
content_alchemy.py - Ø³ÛŒØ³ØªÙ… Ú©ÛŒÙ…ÛŒØ§ÛŒ Ù…Ø­ØªÙˆØ§
Advanced content creation and management system
"""

import asyncio
import json
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
import re
import random
from pathlib import Path
import hashlib

logger = logging.getLogger(__name__)

class ContentAlchemy:
    """
    Ø³ÛŒØ³ØªÙ… Ú©ÛŒÙ…ÛŒØ§ÛŒ Ù…Ø­ØªÙˆØ§ - ØªÙˆÙ„ÛŒØ¯ Ùˆ Ù…Ø¯ÛŒØ±ÛŒØª Ù…Ø­ØªÙˆØ§ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯
    Advanced content creation and management system
    """
    
    def __init__(self, nora_core, telegram_client):
        self.nora_core = nora_core
        self.telegram_client = telegram_client
        self.content_templates = {}
        self.posting_schedule = {}
        self.content_queue = []
        self.aria_style_patterns = {}
        
        # Load configurations
        self.config = self._load_content_config()
        self._load_aria_patterns()
        
    def _load_content_config(self) -> Dict:
        """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ØªÙ†Ø¸ÛŒÙ…Ø§Øª ØªÙˆÙ„ÛŒØ¯ Ù…Ø­ØªÙˆØ§"""
        try:
            with open('config/content_creation.json', 'r', encoding='utf-8') as f:
                return json.load(f)
        except FileNotFoundError:
            return self._create_default_content_config()
            
    def _create_default_content_config(self) -> Dict:
        """Ø§ÛŒØ¬Ø§Ø¯ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù¾ÛŒØ´â€ŒÙØ±Ø¶ ØªÙˆÙ„ÛŒØ¯ Ù…Ø­ØªÙˆØ§"""
        config = {
            "autonomous_posting": {
                "enabled": True,
                "frequency": "smart_adaptive",  # Based on engagement and trends
                "peak_hours": ["09:00", "13:00", "18:00", "21:00"],
                "max_posts_per_day": 5,
                "min_interval_hours": 2
            },
            "content_types": {
                "insights": {
                    "weight": 0.3,
                    "sources": ["learning_insights", "trend_analysis", "personal_thoughts"],
                    "style": "analytical_friendly"
                },
                "quotes": {
                    "weight": 0.2,
                    "sources": ["famous_thinkers", "tech_leaders", "original_thoughts"],
                    "style": "inspirational"
                },
                "threads": {
                    "weight": 0.25,
                    "sources": ["deep_topics", "tutorials", "explanations"],
                    "style": "educational_engaging"
                },
                "responses": {
                    "weight": 0.15,
                    "sources": ["trending_topics", "community_questions"],
                    "style": "conversational"
                },
                "announcements": {
                    "weight": 0.1,
                    "sources": ["projects", "achievements", "updates"],
                    "style": "professional_excited"
                }
            },
            "formatting_rules": {
                "use_emojis": True,
                "emoji_frequency": "moderate",
                "hashtag_count": "2-4",
                "line_breaks": "readable",
                "emphasis": ["**bold**", "*italic*", "`code`"],
                "quotes": "Â«Â»",
                "sources": "always_credit"
            },
            "aria_personality_mimicry": {
                "enabled": True,
                "traits": [
                    "curious_analyst",
                    "tech_enthusiast", 
                    "philosophical_thinker",
                    "startup_mentor",
                    "future_visionary"
                ],
                "writing_patterns": [
                    "starts_with_observation",
                    "builds_logical_argument", 
                    "ends_with_question_or_insight",
                    "uses_mixed_persian_english",
                    "references_personal_experience"
                ]
            },
            "quality_control": {
                "min_content_score": 0.7,
                "fact_check": True,
                "bias_detection": True,
                "originality_threshold": 0.8,
                "engagement_prediction": True
            }
        }
        
        Path("config").mkdir(exist_ok=True)
        with open('config/content_creation.json', 'w', encoding='utf-8') as f:
            json.dump(config, f, ensure_ascii=False, indent=2)
            
        return config
        
    def _load_aria_patterns(self):
        """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ù†ÙˆØ´ØªØ§Ø±ÛŒ Ø¢Ø±ÛŒØ§"""
        self.aria_style_patterns = {
            "opening_phrases": [
                "ÛŒÚ©ÛŒ Ø§Ø² Ú†ÛŒØ²Ø§ÛŒÛŒ Ú©Ù‡ Ù‡Ù…ÛŒØ´Ù‡",
                "ØªØ§Ø²Ú¯ÛŒ Ø¯Ø§Ø´ØªÙ… ÙÚ©Ø± Ù…ÛŒâ€ŒÚ©Ø±Ø¯Ù…",
                "Ø¬Ø§Ù„Ø¨Ù‡ Ú©Ù‡",
                "Ø¨Ù‡ Ù†Ø¸Ø±Ù…",
                "Ø§Ø² ØªØ¬Ø±Ø¨Ù‡â€ŒØ§Ù… Ù…ÛŒâ€ŒØªÙˆÙ†Ù… Ø¨Ú¯Ù…",
                "Recently I've been thinking about",
                "One thing that fascinates me is"
            ],
            "transition_phrases": [
                "Ø§Ù…Ø§ Ù†Ú©ØªÙ‡ Ø§ØµÙ„ÛŒ Ø§ÛŒÙ†Ø¬Ø§Ø³Øª Ú©Ù‡",
                "Ø§Ù„Ø¨ØªÙ‡ Ù†Ø¨Ø§ÛŒØ¯ ÙØ±Ø§Ù…ÙˆØ´ Ú©Ù†ÛŒÙ…",
                "Ù†Ú©ØªÙ‡ Ø¬Ø§Ù„Ø¨ Ø§ÛŒÙ†Ù‡ Ú©Ù‡",
                "However, the key point is",
                "What's interesting is that"
            ],
            "conclusion_patterns": [
                "Ø´Ù…Ø§ Ú†Ù‡ ÙÚ©Ø± Ù…ÛŒâ€ŒÚ©Ù†ÛŒØ¯ØŸ",
                "Ù†Ø¸Ø±ØªÙˆÙ† Ú†ÛŒÙ‡ØŸ",
                "Ø¢ÛŒÙ†Ø¯Ù‡ Ú†ÛŒ Ø¨Ø±Ø§Ø´ Ø±Ù‚Ù… Ù…ÛŒâ€ŒØ®ÙˆØ±Ù‡ØŸ",
                "What are your thoughts?",
                "How do you see this evolving?"
            ],
            "hashtag_style": [
                "#Ù‡ÙˆØ´_Ù…ØµÙ†ÙˆØ¹ÛŒ", "#ÙÙ†Ø§ÙˆØ±ÛŒ", "#Ø§Ø³ØªØ§Ø±ØªØ§Ù¾", "#Ú©Ø§Ø±Ø¢ÙØ±ÛŒÙ†ÛŒ",
                "#AI", "#Technology", "#Innovation", "#Future"
            ],
            "emoji_usage": {
                "thinking": "ğŸ¤”ğŸ’­ğŸ§ ",
                "tech": "ğŸ’»ğŸš€âš¡",
                "insights": "ğŸ’¡âœ¨ğŸ”",
                "future": "ğŸ”®ğŸŒŸğŸš€"
            }
        }
        
    async def generate_smart_content(self, context: Dict = None) -> Dict:
        """ØªÙˆÙ„ÛŒØ¯ Ù…Ø­ØªÙˆØ§ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø´Ø±Ø§ÛŒØ· ÙØ¹Ù„ÛŒ"""
        
        # Analyze current trends and context
        current_context = await self._analyze_current_context()
        
        # Decide content type based on context and strategy
        content_type = self._select_optimal_content_type(current_context)
        
        # Generate content based on type
        if content_type == "insights":
            content = await self._generate_insight_post(current_context)
        elif content_type == "quotes":
            content = await self._generate_quote_post(current_context)
        elif content_type == "threads":
            content = await self._generate_thread_post(current_context)
        elif content_type == "responses":
            content = await self._generate_response_post(current_context)
        else:
            content = await self._generate_announcement_post(current_context)
            
        # Apply Aria's style patterns
        styled_content = self._apply_aria_style(content)
        
        # Quality check
        quality_score = await self._assess_content_quality(styled_content)
        
        if quality_score < self.config["quality_control"]["min_content_score"]:
            # Regenerate if quality is too low
            return await self.generate_smart_content(context)
            
        return {
            "content": styled_content,
            "type": content_type,
            "quality_score": quality_score,
            "context": current_context,
            "metadata": {
                "generated_at": datetime.now().isoformat(),
                "aria_style_applied": True,
                "autonomous": True
            }
        }
        
    async def _analyze_current_context(self) -> Dict:
        """ØªØ­Ù„ÛŒÙ„ Ø¨Ø§ÙØª ÙØ¹Ù„ÛŒ Ø¨Ø±Ø§ÛŒ ØªÙˆÙ„ÛŒØ¯ Ù…Ø­ØªÙˆØ§"""
        context = {
            "time_of_day": datetime.now().hour,
            "day_of_week": datetime.now().weekday(),
            "recent_trends": await self._get_trending_topics(),
            "audience_activity": await self._analyze_audience_activity(),
            "last_post_time": await self._get_last_post_time(),
            "engagement_patterns": await self._analyze_recent_engagement()
        }
        
        return context
        
    async def _get_trending_topics(self) -> List[str]:
        """Ø¯Ø±ÛŒØ§ÙØª Ù…ÙˆØ¶ÙˆØ¹Ø§Øª ØªØ±Ù†Ø¯"""
        # This would analyze recent learning data
        return ["Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ", "Ø§Ø³ØªØ§Ø±ØªØ§Ù¾", "Ù…ØªØ§ÙˆØ±Ø³", "Ø¨Ù„Ø§Ú©â€ŒÚ†ÛŒÙ†"]
        
    async def _analyze_audience_activity(self) -> Dict:
        """ØªØ­Ù„ÛŒÙ„ ÙØ¹Ø§Ù„ÛŒØª Ù…Ø®Ø§Ø·Ø¨Ø§Ù†"""
        return {
            "active_users": 150,
            "engagement_rate": 0.08,
            "peak_activity": "18:00-21:00"
        }
        
    async def _get_last_post_time(self) -> Optional[datetime]:
        """Ø²Ù…Ø§Ù† Ø¢Ø®Ø±ÛŒÙ† Ù¾Ø³Øª"""
        # Check database for last post
        return datetime.now() - timedelta(hours=3)
        
    async def _analyze_recent_engagement(self) -> Dict:
        """ØªØ­Ù„ÛŒÙ„ ØªØ¹Ø§Ù…Ù„ Ø§Ø®ÛŒØ±"""
        return {
            "avg_likes": 25,
            "avg_comments": 5,
            "best_performing_type": "insights"
        }
        
    def _select_optimal_content_type(self, context: Dict) -> str:
        """Ø§Ù†ØªØ®Ø§Ø¨ Ø¨Ù‡ØªØ±ÛŒÙ† Ù†ÙˆØ¹ Ù…Ø­ØªÙˆØ§"""
        weights = self.config["content_types"]
        
        # Adjust weights based on context
        if context["time_of_day"] in [9, 13, 18]:  # Peak hours
            weights["insights"]["weight"] *= 1.5
        elif context["time_of_day"] in [21, 22]:  # Evening
            weights["quotes"]["weight"] *= 1.3
            
        # Select based on weighted random
        content_types = list(weights.keys())
        type_weights = [weights[t]["weight"] for t in content_types]
        
        return random.choices(content_types, weights=type_weights)[0]
        
    async def _generate_insight_post(self, context: Dict) -> str:
        """ØªÙˆÙ„ÛŒØ¯ Ù¾Ø³Øª Ø¨ÛŒÙ†Ø´"""
        prompt = f"""
        Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Ø¢Ø±ÛŒØ§ Ù¾ÙˆØ±Ø´Ø¬Ø§Ø¹ÛŒØŒ ÛŒÚ© Ù¾Ø³Øª Ø¨ÛŒÙ†Ø´â€ŒØ¢Ù…ÛŒØ² Ø¯Ø±Ø¨Ø§Ø±Ù‡ ÛŒÚ©ÛŒ Ø§Ø² Ù…ÙˆØ¶ÙˆØ¹Ø§Øª ØªØ±Ù†Ø¯ Ø¨Ù†ÙˆÛŒØ³:
        Ù…ÙˆØ¶ÙˆØ¹Ø§Øª: {', '.join(context.get('recent_trends', []))}
        
        Ø³Ø¨Ú© Ù†ÙˆØ´ØªÙ†:
        - Ø´Ø±ÙˆØ¹ Ø¨Ø§ Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ø´Ø®ØµÛŒ
        - ØªØ­Ù„ÛŒÙ„ Ù…Ù†Ø·Ù‚ÛŒ
        - Ù¾Ø§ÛŒØ§Ù† Ø¨Ø§ Ø³ÙˆØ§Ù„ ÛŒØ§ Ø¨ÛŒÙ†Ø´
        - ØªØ±Ú©ÛŒØ¨ ÙØ§Ø±Ø³ÛŒ Ùˆ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ
        - Ø­Ø¯Ø§Ú©Ø«Ø± 280 Ú©Ø§Ø±Ø§Ú©ØªØ±
        
        Ù…Ø«Ø§Ù„ Ø³Ø§Ø®ØªØ§Ø±:
        "ØªØ§Ø²Ú¯ÛŒ Ø¯Ø§Ø´ØªÙ… ÙÚ©Ø± Ù…ÛŒâ€ŒÚ©Ø±Ø¯Ù… Ú©Ù‡ [Ù…Ø´Ø§Ù‡Ø¯Ù‡] ... Ø§Ù…Ø§ Ù†Ú©ØªÙ‡ Ø§ØµÙ„ÛŒ Ø§ÛŒÙ†Ø¬Ø§Ø³Øª Ú©Ù‡ [ØªØ­Ù„ÛŒÙ„] ... Ø´Ù…Ø§ Ú†Ù‡ ÙÚ©Ø± Ù…ÛŒâ€ŒÚ©Ù†ÛŒØ¯ØŸ"
        """
        
        insight = await self.nora_core.think(prompt)
        return insight
        
    async def _generate_quote_post(self, context: Dict) -> str:
        """ØªÙˆÙ„ÛŒØ¯ Ù¾Ø³Øª Ù†Ù‚Ù„ Ù‚ÙˆÙ„"""
        prompt = f"""
        Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Ø¢Ø±ÛŒØ§ Ù¾ÙˆØ±Ø´Ø¬Ø§Ø¹ÛŒØŒ ÛŒÚ© Ù†Ù‚Ù„ Ù‚ÙˆÙ„ Ø§Ù„Ù‡Ø§Ù…â€ŒØ¨Ø®Ø´ ÛŒØ§ Ø§ØµÙ„ÛŒ Ø¯Ø±Ø¨Ø§Ø±Ù‡ ÙÙ†Ø§ÙˆØ±ÛŒ/Ú©Ø§Ø±Ø¢ÙØ±ÛŒÙ†ÛŒ Ø¨Ù†ÙˆÛŒØ³:
        
        Ø³Ø¨Ú©:
        - Ú©ÙˆØªØ§Ù‡ Ùˆ ØªØ§Ø«ÛŒØ±Ú¯Ø°Ø§Ø±
        - Ù‚Ø§Ø¨Ù„ Ù†Ù‚Ù„ Ù‚ÙˆÙ„
        - Ù…Ø±ØªØ¨Ø· Ø¨Ø§ {context.get('recent_trends', ['ÙÙ†Ø§ÙˆØ±ÛŒ'])[0]}
        - Ø§Ø­Ø³Ø§Ø³Ø§Øª Ù…Ø«Ø¨Øª
        
        ÙØ±Ù…Øª: Ù…ØªÙ† Ù†Ù‚Ù„ Ù‚ÙˆÙ„ + Ù…Ù†Ø¨Ø¹ (Ø§Ú¯Ø± Ù†Ù‚Ù„ Ù‚ÙˆÙ„ Ø§Ø³Øª) ÛŒØ§ ØªÙˆØ¶ÛŒØ­ Ú©ÙˆØªØ§Ù‡ (Ø§Ú¯Ø± Ø§ØµÙ„ÛŒ Ø§Ø³Øª)
        """
        
        quote = await self.nora_core.think(prompt)
        return quote
        
    async def _generate_thread_post(self, context: Dict) -> str:
        """ØªÙˆÙ„ÛŒØ¯ Ù¾Ø³Øª Ø±Ø´ØªÙ‡â€ŒØ§ÛŒ"""
        prompt = f"""
        Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Ø¢Ø±ÛŒØ§ Ù¾ÙˆØ±Ø´Ø¬Ø§Ø¹ÛŒØŒ ÛŒÚ© thread Ú©ÙˆØªØ§Ù‡ 3-4 Ù‚Ø³Ù…ØªÛŒ Ø¯Ø±Ø¨Ø§Ø±Ù‡ Ù…ÙˆØ¶ÙˆØ¹ ØªØ±Ù†Ø¯ Ø¨Ù†ÙˆÛŒØ³:
        Ù…ÙˆØ¶ÙˆØ¹: {context.get('recent_trends', ['Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ'])[0]}
        
        Ø³Ø§Ø®ØªØ§Ø±:
        1/ Ù…Ù‚Ø¯Ù…Ù‡ + hook
        2/ Ù†Ú©ØªÙ‡ Ø§ØµÙ„ÛŒ + ØªÙˆØ¶ÛŒØ­
        3/ Ù…Ø«Ø§Ù„ ÛŒØ§ ØªØ¬Ø±Ø¨Ù‡ Ø´Ø®ØµÛŒ
        4/ Ù†ØªÛŒØ¬Ù‡â€ŒÚ¯ÛŒØ±ÛŒ + Ø³ÙˆØ§Ù„
        
        Ù‡Ø± Ù‚Ø³Ù…Øª Ø­Ø¯Ø§Ú©Ø«Ø± 280 Ú©Ø§Ø±Ø§Ú©ØªØ±
        """
        
        thread = await self.nora_core.think(prompt)
        return thread
        
    async def _generate_response_post(self, context: Dict) -> str:
        """ØªÙˆÙ„ÛŒØ¯ Ù¾Ø³Øª Ù¾Ø§Ø³Ø® Ø¨Ù‡ ØªØ±Ù†Ø¯Ù‡Ø§"""
        prompt = f"""
        Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Ø¢Ø±ÛŒØ§ Ù¾ÙˆØ±Ø´Ø¬Ø§Ø¹ÛŒØŒ Ù¾Ø§Ø³Ø®ÛŒ Ø¨Ù‡ Ù…ÙˆØ¶ÙˆØ¹ Ø¯Ø§Øº Ø±ÙˆØ² Ø¨Ø¯Ù‡:
        Ù…ÙˆØ¶ÙˆØ¹: {context.get('recent_trends', ['ÙÙ†Ø§ÙˆØ±ÛŒ'])[0]}
        
        Ø³Ø¨Ú©:
        - Ù†Ø¸Ø± Ø´Ø®ØµÛŒ Ùˆ ØªØ­Ù„ÛŒÙ„ÛŒ
        - Ù…Ø¨ØªÙ†ÛŒ Ø¨Ø± ØªØ¬Ø±Ø¨Ù‡
        - Ù‚Ø§Ø¨Ù„ Ø¨Ø­Ø«
        - Ú©Ù…ÛŒ Ø¬Ù†Ø¬Ø§Ù„ÛŒ Ø§Ù…Ø§ Ø³Ø§Ø²Ù†Ø¯Ù‡
        """
        
        response = await self.nora_core.think(prompt)
        return response
        
    async def _generate_announcement_post(self, context: Dict) -> str:
        """ØªÙˆÙ„ÛŒØ¯ Ù¾Ø³Øª Ø§Ø¹Ù„Ø§Ù†"""
        prompt = """
        Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Ø¢Ø±ÛŒØ§ Ù¾ÙˆØ±Ø´Ø¬Ø§Ø¹ÛŒØŒ ÛŒÚ© Ø§Ø¹Ù„Ø§Ù† Ú©ÙˆØªØ§Ù‡ Ø¯Ø±Ø¨Ø§Ø±Ù‡ Ù¾ÛŒØ´Ø±ÙØª Ù†ÙˆØ±Ø§ ÛŒØ§ Ù¾Ø±ÙˆÚ˜Ù‡â€ŒÙ‡Ø§ÛŒØª Ø¨Ù†ÙˆÛŒØ³:
        
        Ø³Ø¨Ú©:
        - Ù‡ÛŒØ¬Ø§Ù†â€ŒØ§Ù†Ú¯ÛŒØ² Ø§Ù…Ø§ Ù…ØªÙˆØ§Ø¶Ø¹Ø§Ù†Ù‡
        - Ø´Ø§Ù…Ù„ Ø¬Ø²Ø¦ÛŒØ§Øª ÙÙ†ÛŒ Ø¬Ø§Ù„Ø¨
        - Ø¯Ø¹ÙˆØª Ø¨Ù‡ Ù…Ø´Ø§Ø±Ú©Øª ÛŒØ§ ÙÛŒØ¯Ø¨Ú©
        """
        
        announcement = await self.nora_core.think(prompt)
        return announcement
        
    def _apply_aria_style(self, content: str) -> str:
        """Ø§Ø¹Ù…Ø§Ù„ Ø³Ø¨Ú© Ù†ÙˆØ´ØªØ§Ø±ÛŒ Ø¢Ø±ÛŒØ§"""
        
        # Add appropriate emojis
        content = self._add_contextual_emojis(content)
        
        # Format with proper emphasis
        content = self._apply_text_formatting(content)
        
        # Add relevant hashtags
        content = self._add_smart_hashtags(content)
        
        # Ensure proper line breaks for readability
        content = self._optimize_readability(content)
        
        return content
        
    def _add_contextual_emojis(self, content: str) -> str:
        """Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø§ÛŒÙ…ÙˆØ¬ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…Ù†Ø§Ø³Ø¨"""
        emoji_map = {
            r'ÙÚ©Ø±|think|ØªØ­Ù„ÛŒÙ„': 'ğŸ¤”',
            r'ÙÙ†Ø§ÙˆØ±ÛŒ|technology|tech': 'ğŸ’»',
            r'Ø¢ÛŒÙ†Ø¯Ù‡|future': 'ğŸš€',
            r'Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ|AI': 'ğŸ§ ',
            r'Ù†ÙˆØ¢ÙˆØ±ÛŒ|innovation': 'ğŸ’¡',
            r'Ø§Ø³ØªØ§Ø±ØªØ§Ù¾|startup': 'âš¡'
        }
        
        for pattern, emoji in emoji_map.items():
            if re.search(pattern, content, re.IGNORECASE):
                if emoji not in content:
                    content = f"{emoji} {content}"
                break
                
        return content
        
    def _apply_text_formatting(self, content: str) -> str:
        """Ø§Ø¹Ù…Ø§Ù„ Ù‚Ø§Ù„Ø¨â€ŒØ¨Ù†Ø¯ÛŒ Ù…ØªÙ†"""
        
        # Bold for key concepts
        key_concepts = [
            r'Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ', r'AI', r'blockchain', r'Ù…ØªØ§ÙˆØ±Ø³',
            r'Ø§Ø³ØªØ§Ø±ØªØ§Ù¾', r'startup', r'Ù†ÙˆØ¢ÙˆØ±ÛŒ', r'innovation'
        ]
        
        for concept in key_concepts:
            content = re.sub(f'({concept})', r'**\1**', content, flags=re.IGNORECASE)
            
        # Italic for emphasis words
        emphasis_words = [r'ÙˆØ§Ù‚Ø¹Ø§Ù‹', r'really', r'Ø§Ù„Ø¨ØªÙ‡', r'obviously', r'Ø¬Ø§Ù„Ø¨', r'interesting']
        
        for word in emphasis_words:
            content = re.sub(f'({word})', r'*\1*', content, flags=re.IGNORECASE)
            
        return content
        
    def _add_smart_hashtags(self, content: str) -> str:
        """Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù‡Ø´ØªÚ¯â€ŒÙ‡Ø§ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯"""
        hashtags = []
        
        # Analyze content for relevant hashtags
        if any(word in content.lower() for word in ['Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ', 'ai', 'artificial']):
            hashtags.append('#Ù‡ÙˆØ´_Ù…ØµÙ†ÙˆØ¹ÛŒ')
            hashtags.append('#AI')
            
        if any(word in content.lower() for word in ['ÙÙ†Ø§ÙˆØ±ÛŒ', 'technology', 'tech']):
            hashtags.append('#ÙÙ†Ø§ÙˆØ±ÛŒ')
            hashtags.append('#Technology')
            
        if any(word in content.lower() for word in ['Ø§Ø³ØªØ§Ø±ØªØ§Ù¾', 'startup']):
            hashtags.append('#Ø§Ø³ØªØ§Ø±ØªØ§Ù¾')
            hashtags.append('#Startup')
            
        # Add signature hashtag
        hashtags.append('#Ø¢Ø±ÛŒØ§_Ù¾ÙˆØ±Ø´Ø¬Ø§Ø¹ÛŒ')
        
        # Limit to 4 hashtags max
        selected_hashtags = hashtags[:4]
        
        if selected_hashtags:
            content += f"\n\n{' '.join(selected_hashtags)}"
            
        return content
        
    def _optimize_readability(self, content: str) -> str:
        """Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø®ÙˆØ§Ù†Ø§ÛŒÛŒ"""
        
        # Add line breaks after sentences for better readability
        content = re.sub(r'(\. )([A-ZÃ€-Ã¿Ø¢-ÛŒ])', r'\1\n\n\2', content)
        
        # Ensure proper spacing around emojis
        content = re.sub(r'([^\s])([ğŸ”¥ğŸ’¡ğŸš€ğŸ¤”ğŸ’»ğŸ§ âš¡âœ¨])', r'\1 \2', content)
        content = re.sub(r'([ğŸ”¥ğŸ’¡ğŸš€ğŸ¤”ğŸ’»ğŸ§ âš¡âœ¨])([^\s])', r'\1 \2', content)
        
        return content.strip()
        
    async def _assess_content_quality(self, content: str) -> float:
        """Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ú©ÛŒÙÛŒØª Ù…Ø­ØªÙˆØ§"""
        
        quality_factors = {
            "length": self._assess_length_quality(content),
            "engagement": self._assess_engagement_potential(content),
            "originality": await self._assess_originality(content),
            "readability": self._assess_readability(content),
            "style_consistency": self._assess_style_consistency(content)
        }
        
        # Weighted average
        weights = {"length": 0.2, "engagement": 0.3, "originality": 0.3, "readability": 0.1, "style_consistency": 0.1}
        
        total_score = sum(quality_factors[factor] * weights[factor] for factor in quality_factors)
        
        return total_score
        
    def _assess_length_quality(self, content: str) -> float:
        """Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ú©ÛŒÙÛŒØª Ø·ÙˆÙ„ Ù…Ø­ØªÙˆØ§"""
        length = len(content)
        if 100 <= length <= 500:  # Optimal range
            return 1.0
        elif 50 <= length < 100 or 500 < length <= 800:
            return 0.8
        elif length < 50 or length > 800:
            return 0.5
        return 0.3
        
    def _assess_engagement_potential(self, content: str) -> float:
        """Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù¾ØªØ§Ù†Ø³ÛŒÙ„ ØªØ¹Ø§Ù…Ù„"""
        score = 0.5  # Base score
        
        # Questions increase engagement
        if '?' in content or 'ØŸ' in content:
            score += 0.2
            
        # Emojis increase engagement
        emoji_count = len(re.findall(r'[ğŸ”¥ğŸ’¡ğŸš€ğŸ¤”ğŸ’»ğŸ§ âš¡âœ¨]', content))
        score += min(0.2, emoji_count * 0.05)
        
        # Call to action words
        cta_words = ['ÙÚ©Ø± Ù…ÛŒâ€ŒÚ©Ù†ÛŒØ¯', 'Ù†Ø¸Ø±ØªÙˆÙ†', 'ØªØ¬Ø±Ø¨Ù‡', 'what do you think']
        if any(word in content.lower() for word in cta_words):
            score += 0.1
            
        return min(1.0, score)
        
    async def _assess_originality(self, content: str) -> float:
        """Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø§ØµØ§Ù„Øª Ù…Ø­ØªÙˆØ§"""
        # Simple originality check
        content_hash = hashlib.md5(content.encode()).hexdigest()
        
        # Check against recent posts (simplified)
        try:
            with open('data/content_history.jsonl', 'r', encoding='utf-8') as f:
                recent_hashes = [json.loads(line).get('hash') for line in f.readlines()[-100:]]
                
            if content_hash in recent_hashes:
                return 0.3  # Low originality
            else:
                return 0.9  # High originality
        except FileNotFoundError:
            return 0.9
            
    def _assess_readability(self, content: str) -> float:
        """Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø®ÙˆØ§Ù†Ø§ÛŒÛŒ"""
        
        # Check for proper formatting
        score = 0.5
        
        if re.search(r'\*\*.*\*\*', content):  # Has bold text
            score += 0.1
        if re.search(r'\n\n', content):  # Has proper line breaks
            score += 0.1
        if len(content.split()) < 100:  # Not too long
            score += 0.2
        if content.count('.') > 0:  # Has proper sentences
            score += 0.1
            
        return min(1.0, score)
        
    def _assess_style_consistency(self, content: str) -> float:
        """Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø³Ø§Ø²Ú¯Ø§Ø±ÛŒ Ø³Ø¨Ú©"""
        
        # Check for Aria's style patterns
        style_score = 0.5
        
        opening_patterns = self.aria_style_patterns["opening_phrases"]
        if any(pattern in content for pattern in opening_patterns):
            style_score += 0.2
            
        if '#Ø¢Ø±ÛŒØ§_Ù¾ÙˆØ±Ø´Ø¬Ø§Ø¹ÛŒ' in content:
            style_score += 0.1
            
        # Check for Persian-English mix
        persian_chars = len(re.findall(r'[\u0600-\u06FF]', content))
        english_chars = len(re.findall(r'[a-zA-Z]', content))
        total_chars = persian_chars + english_chars
        
        if total_chars > 0:
            persian_ratio = persian_chars / total_chars
            if 0.3 <= persian_ratio <= 0.7:  # Good mix
                style_score += 0.2
                
        return min(1.0, style_score)
        
    async def schedule_smart_posting(self):
        """Ø²Ù…Ø§Ù†â€ŒØ¨Ù†Ø¯ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø§Ù†ØªØ´Ø§Ø±"""
        
        if not self.config["autonomous_posting"]["enabled"]:
            return
            
        # Check if it's time to post
        if await self._should_post_now():
            content_data = await self.generate_smart_content()
            
            # Add to queue for review or direct posting
            await self._queue_or_post_content(content_data)
            
    async def _should_post_now(self) -> bool:
        """ØªØ´Ø®ÛŒØµ Ø²Ù…Ø§Ù† Ù…Ù†Ø§Ø³Ø¨ Ù¾Ø³Øª"""
        
        current_hour = datetime.now().hour
        peak_hours = [int(h.split(':')[0]) for h in self.config["autonomous_posting"]["peak_hours"]]
        
        # Check if it's peak hour
        if current_hour not in peak_hours:
            return False
            
        # Check minimum interval
        last_post_time = await self._get_last_post_time()
        if last_post_time:
            hours_since_last = (datetime.now() - last_post_time).total_seconds() / 3600
            if hours_since_last < self.config["autonomous_posting"]["min_interval_hours"]:
                return False
                
        # Check daily limit
        today_posts = await self._count_today_posts()
        if today_posts >= self.config["autonomous_posting"]["max_posts_per_day"]:
            return False
            
        return True
        
    async def _count_today_posts(self) -> int:
        """Ø´Ù…Ø§Ø±Ø´ Ù¾Ø³Øªâ€ŒÙ‡Ø§ÛŒ Ø§Ù…Ø±ÙˆØ²"""
        # This would check the database
        return 2  # Placeholder
        
    async def _queue_or_post_content(self, content_data: Dict):
        """Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø¨Ù‡ ØµÙ ÛŒØ§ Ø§Ù†ØªØ´Ø§Ø± Ù…Ø³ØªÙ‚ÛŒÙ…"""
        
        # For high-quality content, post directly
        if content_data["quality_score"] > 0.85:
            await self._post_content_immediately(content_data)
        else:
            # Add to queue for review
            self.content_queue.append(content_data)
            
        # Log the action
        await self._log_content_action(content_data)
        
    async def _post_content_immediately(self, content_data: Dict):
        """Ø§Ù†ØªØ´Ø§Ø± ÙÙˆØ±ÛŒ Ù…Ø­ØªÙˆØ§"""
        
        content = content_data["content"]
        
        # Post to Telegram
        success = await self.telegram_client.post_to_channel(content)
        
        if success:
            # Store in content history
            await self._store_content_history(content_data)
            logger.info(f"âœ… Auto-posted content: {content[:50]}...")
        else:
            logger.error("âŒ Failed to auto-post content")
            
    async def _store_content_history(self, content_data: Dict):
        """Ø°Ø®ÛŒØ±Ù‡ ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ù…Ø­ØªÙˆØ§"""
        
        history_entry = {
            "timestamp": datetime.now().isoformat(),
            "content": content_data["content"],
            "type": content_data["type"],
            "quality_score": content_data["quality_score"],
            "hash": hashlib.md5(content_data["content"].encode()).hexdigest(),
            "autonomous": content_data["metadata"]["autonomous"]
        }
        
        with open('data/content_history.jsonl', 'a', encoding='utf-8') as f:
            f.write(json.dumps(history_entry, ensure_ascii=False) + '\n')
            
    async def _log_content_action(self, content_data: Dict):
        """Ø«Ø¨Øª Ù„Ø§Ú¯ Ø¹Ù…Ù„ÛŒØ§Øª Ù…Ø­ØªÙˆØ§"""
        
        log_entry = {
            "timestamp": datetime.now().isoformat(),
            "action": "content_generated",
            "type": content_data["type"],
            "quality_score": content_data["quality_score"],
            "content_preview": content_data["content"][:100] + "..."
        }
        
        with open('logs/content_alchemy.jsonl', 'a', encoding='utf-8') as f:
            f.write(json.dumps(log_entry, ensure_ascii=False) + '\n')
            
    async def create_content_from_learning(self, learning_insights: List[Dict]) -> Dict:
        """ØªÙˆÙ„ÛŒØ¯ Ù…Ø­ØªÙˆØ§ Ø§Ø² Ø¨ÛŒÙ†Ø´â€ŒÙ‡Ø§ÛŒ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ"""
        
        # Select best insights
        high_value_insights = [
            insight for insight in learning_insights 
            if insight.get('learning_value', 0) > 0.7
        ]
        
        if not high_value_insights:
            return None
            
        # Choose one insight to expand
        selected_insight = random.choice(high_value_insights)
        
        # Generate content based on insight
        prompt = f"""
        Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Ø¢Ø±ÛŒØ§ Ù¾ÙˆØ±Ø´Ø¬Ø§Ø¹ÛŒØŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§ÛŒÙ† Ø¨ÛŒÙ†Ø´ Ø¬Ø¯ÛŒØ¯ÛŒ Ú©Ù‡ ÛŒØ§Ø¯ Ú¯Ø±ÙØªÙ…ØŒ ÛŒÚ© Ù¾Ø³Øª Ø¬Ø°Ø§Ø¨ Ø¨Ù†ÙˆÛŒØ³:
        
        Ø¨ÛŒÙ†Ø´: {selected_insight.get('content', '')}
        Ù…Ù†Ø¨Ø¹: {selected_insight.get('source', '')}
        
        Ø³Ø¨Ú©:
        - Ø´Ø±ÙˆØ¹ Ø¨Ø§ "ØªØ§Ø²Ú¯ÛŒ ÛŒØ§Ø¯ Ú¯Ø±ÙØªÙ… Ú©Ù‡..."
        - Ø§Ø±ØªØ¨Ø§Ø· Ø¨Ø§ ØªØ¬Ø±Ø¨Ù‡ Ø´Ø®ØµÛŒ
        - Ø¨ÛŒÙ†Ø´ Ø§ØµÙ„ÛŒ
        - Ø³ÙˆØ§Ù„ Ø¨Ø±Ø§ÛŒ ØªØ¹Ø§Ù…Ù„
        
        Ø­Ø¯Ø§Ú©Ø«Ø± 400 Ú©Ø§Ø±Ø§Ú©ØªØ±
        """
        
        content = await self.nora_core.think(prompt)
        
        return {
            "content": self._apply_aria_style(content),
            "type": "learning_insight",
            "source_insight": selected_insight,
            "quality_score": 0.8,
            "metadata": {
                "generated_from": "learning",
                "source": selected_insight.get('source'),
                "generated_at": datetime.now().isoformat()
            }
        }
        
    async def run(self):
        """Ø­Ù„Ù‚Ù‡ Ø§ØµÙ„ÛŒ Ø³ÛŒØ³ØªÙ… Ú©ÛŒÙ…ÛŒØ§ÛŒ Ù…Ø­ØªÙˆØ§"""
        logger.info("ğŸ¨ Content Alchemy system is now active")
        
        while True:
            try:
                # Smart posting schedule
                await self.schedule_smart_posting()
                
                # Process content queue
                await self._process_content_queue()
                
                # Generate content from recent learning
                await self._generate_from_recent_learning()
                
                # Clean up old content
                await self._cleanup_old_content()
                
                # Sleep for 15 minutes
                await asyncio.sleep(900)
                
            except Exception as e:
                logger.error(f"Error in Content Alchemy system: {e}")
                await asyncio.sleep(300)
                
    async def _process_content_queue(self):
        """Ù¾Ø±Ø¯Ø§Ø²Ø´ ØµÙ Ù…Ø­ØªÙˆØ§"""
        
        if not self.content_queue:
            return
            
        # Process queued content
        for content_data in self.content_queue[:3]:  # Process max 3 at a time
            # Re-evaluate quality
            updated_score = await self._assess_content_quality(content_data["content"])
            
            if updated_score > 0.75:
                await self._post_content_immediately(content_data)
                self.content_queue.remove(content_data)
                
    async def _generate_from_recent_learning(self):
        """ØªÙˆÙ„ÛŒØ¯ Ù…Ø­ØªÙˆØ§ Ø§Ø² ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ø§Ø®ÛŒØ±"""
        
        # Check for recent learning insights
        try:
            with open('data/learning_insights.json', 'r', encoding='utf-8') as f:
                insights = json.load(f)
                
            recent_insights = insights.get('recent_insights', [])
            
            if recent_insights and random.random() < 0.3:  # 30% chance
                content_data = await self.create_content_from_learning(recent_insights)
                if content_data:
                    await self._queue_or_post_content(content_data)
                    
        except FileNotFoundError:
            pass
            
    async def _cleanup_old_content(self):
        """Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ù…Ø­ØªÙˆØ§ÛŒ Ù‚Ø¯ÛŒÙ…ÛŒ"""
        
        # Remove old content from queue (older than 24 hours)
        current_time = datetime.now()
        
        self.content_queue = [
            content for content in self.content_queue
            if (current_time - datetime.fromisoformat(content["metadata"]["generated_at"])).total_seconds() < 86400
        ]
