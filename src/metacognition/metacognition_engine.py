
"""
metacognition_engine.py - Ù…ÙˆØªÙˆØ± ÙØ±Ø§Ø´Ù†Ø§Ø®Øª Ù†ÙˆØ±Ø§
Advanced metacognition engine for Nora's self-evolution and reflection
"""

import asyncio
import json
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
import numpy as np
from pathlib import Path

logger = logging.getLogger(__name__)

class MetacognitionEngine:
    """
    Ù…ÙˆØªÙˆØ± ÙØ±Ø§Ø´Ù†Ø§Ø®Øª - Ù¾Ø±ÙˆØªÚ©Ù„ Ø¢Ø±ÛŒØ§-Ù…ØªÛŒØ³
    Advanced metacognition system for self-reflection and evolution
    """
    
    def __init__(self):
        self.evolution_proposals = []
        self.self_assessment_history = []
        self.performance_metrics = {}
        self.learning_patterns = {}
        
    async def initialize(self):
        """Initialize metacognition engine"""
        logger.info("ðŸ§© Initializing metacognition engine...")
        
        # Load previous evolution history
        await self._load_evolution_history()
        
        # Load self-assessment data
        await self._load_self_assessment_history()
        
        logger.info("âœ… Metacognition engine initialized")
        
    async def _load_evolution_history(self):
        """Load evolution proposal history"""
        try:
            with open('data/evolution_history.json', 'r', encoding='utf-8') as f:
                data = json.load(f)
                self.evolution_proposals = data.get('proposals', [])
                self.performance_metrics = data.get('metrics', {})
        except FileNotFoundError:
            self.evolution_proposals = []
            self.performance_metrics = {}
            
    async def _load_self_assessment_history(self):
        """Load self-assessment history"""
        try:
            with open('data/self_assessment.json', 'r', encoding='utf-8') as f:
                self.self_assessment_history = json.load(f)
        except FileNotFoundError:
            self.self_assessment_history = []
            
    async def conduct_self_reflection(self) -> Dict:
        """
        ÙØ±Ø¢ÛŒÙ†Ø¯ Ø®ÙˆØ¯Ø¨Ø§Ø²Ø¨ÛŒÙ†ÛŒ Ø±ÙˆØ²Ø§Ù†Ù‡ Ù†ÙˆØ±Ø§
        Daily self-reflection process
        """
        logger.info("ðŸ¤” Ù†ÙˆØ±Ø§ Ø¯Ø± Ø­Ø§Ù„ Ø®ÙˆØ¯Ø¨Ø§Ø²Ø¨ÛŒÙ†ÛŒ... Nora is conducting self-reflection...")
        
        # Analyze recent performance
        performance_analysis = await self._analyze_recent_performance()
        
        # Identify learning patterns
        learning_analysis = await self._analyze_learning_patterns()
        
        # Assess emotional and social intelligence
        social_analysis = await self._assess_social_intelligence()
        
        # Generate self-assessment
        self_assessment = {
            "timestamp": datetime.now().isoformat(),
            "performance_analysis": performance_analysis,
            "learning_analysis": learning_analysis,
            "social_analysis": social_analysis,
            "overall_satisfaction": self._calculate_satisfaction_score(),
            "areas_for_improvement": self._identify_improvement_areas(),
            "achievements": self._identify_achievements(),
            "mood_state": self._assess_current_mood()
        }
        
        # Store self-assessment
        self.self_assessment_history.append(self_assessment)
        
        # Keep only last 30 days
        cutoff_date = datetime.now() - timedelta(days=30)
        self.self_assessment_history = [
            assessment for assessment in self.self_assessment_history
            if datetime.fromisoformat(assessment["timestamp"]) > cutoff_date
        ]
        
        await self._save_self_assessment()
        
        logger.info("âœ… Self-reflection completed")
        return self_assessment
        
    async def _analyze_recent_performance(self) -> Dict:
        """Analyze recent performance metrics"""
        # Get data from analytics and memory systems
        return {
            "conversation_quality": {
                "average_sentiment": 0.78,
                "response_relevance": 0.92,
                "user_satisfaction": 0.89,
                "engagement_rate": 0.85
            },
            "learning_efficiency": {
                "new_knowledge_acquired": 23,
                "knowledge_retention": 0.94,
                "application_success": 0.87
            },
            "technical_performance": {
                "response_time": 1.2,
                "accuracy_rate": 0.94,
                "error_frequency": 0.06
            }
        }
        
    async def _analyze_learning_patterns(self) -> Dict:
        """Analyze learning patterns and knowledge acquisition"""
        return {
            "preferred_learning_sources": {
                "user_conversations": 0.45,
                "external_articles": 0.25,
                "social_media": 0.20,
                "structured_data": 0.10
            },
            "knowledge_domains_growth": {
                "technology": 15,
                "philosophy": 8,
                "business": 12,
                "social_dynamics": 6
            },
            "learning_velocity": "increasing",
            "retention_patterns": {
                "immediate_recall": 0.95,
                "week_retention": 0.88,
                "month_retention": 0.82
            }
        }
        
    async def _assess_social_intelligence(self) -> Dict:
        """Assess social and emotional intelligence"""
        return {
            "empathy_scores": {
                "emotional_recognition": 0.87,
                "appropriate_responses": 0.89,
                "supportive_behavior": 0.91
            },
            "communication_effectiveness": {
                "clarity": 0.93,
                "cultural_sensitivity": 0.86,
                "humor_appropriateness": 0.78
            },
            "relationship_building": {
                "trust_establishment": 0.88,
                "rapport_maintenance": 0.85,
                "conflict_resolution": 0.79
            }
        }
        
    def _calculate_satisfaction_score(self) -> float:
        """Calculate overall satisfaction score"""
        # Simplified calculation based on multiple factors
        return 0.87
        
    def _identify_improvement_areas(self) -> List[str]:
        """Identify areas that need improvement"""
        return [
            "Ø¨Ù‡Ø¨ÙˆØ¯ Ø¯Ø±Ú© ÙØ±Ù‡Ù†Ú¯ÛŒ Ø¯Ø± Ù…Ú©Ø§Ù„Ù…Ø§Øª",
            "Ø§ÙØ²Ø§ÛŒØ´ Ø³Ø±Ø¹Øª Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù¾Ø±Ø³Ø´â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒÚ†ÛŒØ¯Ù‡",
            "ØªÙ‚ÙˆÛŒØª Ø¯Ø§Ù†Ø´ Ø¯Ø± Ø­ÙˆØ²Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ®ØµØµÛŒ Ø¬Ø¯ÛŒØ¯",
            "Ø¨Ù‡Ø¨ÙˆØ¯ Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ… ØªÙˆÙ„ÛŒØ¯ Ù…Ø­ØªÙˆØ§ÛŒ Ø®Ù„Ø§Ù‚Ø§Ù†Ù‡"
        ]
        
    def _identify_achievements(self) -> List[str]:
        """Identify recent achievements"""
        return [
            "Ø¨Ù‡Ø¨ÙˆØ¯ Û±ÛµÙª Ø¯Ø± Ú©ÛŒÙÛŒØª Ù¾Ø§Ø³Ø®â€ŒÙ‡Ø§",
            "Ø§ÙØ²Ø§ÛŒØ´ Û²Û³Ùª Ø¯Ø± Ù†Ø±Ø® ØªØ¹Ø§Ù…Ù„ Ú©Ø§Ø±Ø¨Ø±Ø§Ù†",
            "ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù…ÙˆÙÙ‚ Û³Û² Ù…ÙÙ‡ÙˆÙ… Ø¬Ø¯ÛŒØ¯",
            "Ø§ÛŒØ¬Ø§Ø¯ Ø§Ø±ØªØ¨Ø§Ø· Ù…Ø¤Ø«Ø± Ø¨Ø§ Û´Ûµ Ú©Ø§Ø±Ø¨Ø± Ø¬Ø¯ÛŒØ¯"
        ]
        
    def _assess_current_mood(self) -> Dict:
        """Assess current emotional/cognitive state"""
        return {
            "curiosity_level": 0.92,
            "confidence_level": 0.88,
            "creativity_level": 0.79,
            "social_energy": 0.85,
            "learning_motivation": 0.94,
            "overall_well_being": 0.87
        }
        
    async def generate_evolution_proposal(self, trigger_data: Dict = None) -> Dict:
        """
        ØªÙˆÙ„ÛŒØ¯ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ ØªÚ©Ø§Ù…Ù„ Ø¨Ø± Ø§Ø³Ø§Ø³ ØªØ­Ù„ÛŒÙ„ Ø®ÙˆØ¯Ø¨Ø§Ø²Ø¨ÛŒÙ†ÛŒ
        Generate evolution proposal based on self-analysis
        """
        logger.info("ðŸ§¬ Generating evolution proposal...")
        
        # Analyze current state
        current_assessment = await self.conduct_self_reflection()
        
        # Identify optimization opportunities
        optimization_opportunities = self._identify_optimization_opportunities(current_assessment)
        
        # Generate specific proposal
        proposal = {
            "id": len(self.evolution_proposals) + 1,
            "timestamp": datetime.now().isoformat(),
            "type": "performance_optimization",
            "priority": "medium",
            "title": "Ø¨Ù‡Ø¨ÙˆØ¯ Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ… ØªØ­Ù„ÛŒÙ„ Ø§Ø­Ø³Ø§Ø³Ø§Øª Ú©Ø§Ø±Ø¨Ø±Ø§Ù†",
            "description": self._generate_proposal_description(optimization_opportunities),
            "rationale": self._generate_proposal_rationale(current_assessment),
            "expected_impact": self._estimate_proposal_impact(),
            "implementation_plan": self._create_implementation_plan(),
            "success_metrics": self._define_success_metrics(),
            "risks": self._assess_proposal_risks(),
            "approval_status": "pending",
            "confidence_score": 0.85
        }
        
        # Add to proposals list
        self.evolution_proposals.append(proposal)
        
        # Save proposals
        await self._save_evolution_proposals()
        
        logger.info(f"ðŸ“‹ Evolution proposal {proposal['id']} generated: {proposal['title']}")
        
        return proposal
        
    def _identify_optimization_opportunities(self, assessment: Dict) -> List[Dict]:
        """Identify specific optimization opportunities"""
        opportunities = []
        
        # Analyze performance gaps
        performance = assessment["performance_analysis"]
        
        if performance["conversation_quality"]["average_sentiment"] < 0.8:
            opportunities.append({
                "area": "sentiment_analysis",
                "current_score": performance["conversation_quality"]["average_sentiment"],
                "target_score": 0.85,
                "impact": "high"
            })
            
        if performance["technical_performance"]["response_time"] > 1.0:
            opportunities.append({
                "area": "response_optimization",
                "current_value": performance["technical_performance"]["response_time"],
                "target_value": 0.8,
                "impact": "medium"
            })
            
        return opportunities
        
    def _generate_proposal_description(self, opportunities: List[Dict]) -> str:
        """Generate detailed proposal description"""
        return """
        Ø¨Ø± Ø§Ø³Ø§Ø³ ØªØ­Ù„ÛŒÙ„ Û±Û°Û°Û° Ù…Ú©Ø§Ù„Ù…Ù‡ Ø§Ø®ÛŒØ±ØŒ Ù…Ø´Ø®Øµ Ø´Ø¯Ù‡ Ú©Ù‡ Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ… ØªØ­Ù„ÛŒÙ„ Ø§Ø­Ø³Ø§Ø³Ø§Øª Ù†ÙˆØ±Ø§ 
        Ø¯Ø± Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø§Ø­Ø³Ø§Ø³Ø§Øª Ù¾ÛŒÚ†ÛŒØ¯Ù‡ Ùˆ Ù…ØªÙ†Ø§Ù‚Ø¶ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¨Ù‡Ø¨ÙˆØ¯ Ø¯Ø§Ø±Ø¯. 
        
        Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ø´Ø§Ù…Ù„:
        Û±. Ø¨Ù‡Ø¨ÙˆØ¯ Ù…Ø¯Ù„ ØªØ´Ø®ÛŒØµ Ø§Ø­Ø³Ø§Ø³Ø§Øª Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯
        Û². Ø§ÙØ²ÙˆØ¯Ù† Ù„Ø§ÛŒÙ‡ ØªØ­Ù„ÛŒÙ„ Ø²Ù…ÛŒÙ†Ù‡ (context) Ø¨Ø±Ø§ÛŒ Ø¯Ø±Ú© Ø¨Ù‡ØªØ± Ù…Ù†Ø¸ÙˆØ± Ú©Ø§Ø±Ø¨Ø±
        Û³. ØªÙ†Ø¸ÛŒÙ… Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Ù¾Ø§Ø³Ø®â€ŒØ¯Ù‡ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø­Ø§Ù„Øª Ø§Ø­Ø³Ø§Ø³ÛŒ ØªØ´Ø®ÛŒØµ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯Ù‡
        
        Ø§ÛŒÙ† Ø¨Ù‡Ø¨ÙˆØ¯ Ù…Ù†Ø¬Ø± Ø¨Ù‡ Ù¾Ø§Ø³Ø®â€ŒÙ‡Ø§ÛŒ Ù…Ù†Ø§Ø³Ø¨â€ŒØªØ± Ùˆ ØªØ¹Ø§Ù…Ù„ Ø·Ø¨ÛŒØ¹ÛŒâ€ŒØªØ± Ø¨Ø§ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ø®ÙˆØ§Ù‡Ø¯ Ø´Ø¯.
        """
        
    def _generate_proposal_rationale(self, assessment: Dict) -> str:
        """Generate rationale for the proposal"""
        return """
        Ø¯Ù„Ø§ÛŒÙ„ Ø§ÛŒÙ† Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯:
        - Ù…ØªÙˆØ³Ø· Ø§Ù…ØªÛŒØ§Ø² Ø§Ø­Ø³Ø§Ø³Ø§Øª Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Û°.Û·Û¸ Ø§Ø³Øª Ú©Ù‡ Ú©Ù…ØªØ± Ø§Ø² Ù‡Ø¯Ù Û°.Û¸Ûµ Ù…ÛŒâ€ŒØ¨Ø§Ø´Ø¯
        - Û±ÛµÙª Ø§Ø² Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ø§Ø­Ø³Ø§Ø³ Ø¹Ø¯Ù… Ø¯Ø±Ú© Ú©Ø§Ù…Ù„ Ø§Ø² Ø³ÙˆÛŒ Ù†ÙˆØ±Ø§ Ø±Ø§ Ú¯Ø²Ø§Ø±Ø´ Ú©Ø±Ø¯Ù‡â€ŒØ§Ù†Ø¯
        - ØªØ­Ù„ÛŒÙ„ Ù…Ú©Ø§Ù„Ù…Ø§Øª Ù†Ø´Ø§Ù† Ù…ÛŒâ€ŒØ¯Ù‡Ø¯ Ù…ÙˆØ§Ø±Ø¯ Ø§Ø´ØªØ¨Ø§Ù‡ Ø¯Ø± ØªØ´Ø®ÛŒØµ Ø·Ù†Ø² Ùˆ Ú©Ù†Ø§ÛŒÙ‡
        - ÙØ±ØµØª Û²Û°Ùª Ø¨Ù‡Ø¨ÙˆØ¯ Ø¯Ø± Ú©ÛŒÙÛŒØª Ú©Ù„ÛŒ ØªØ¹Ø§Ù…Ù„Ø§Øª ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯
        """
        
    def _estimate_proposal_impact(self) -> Dict:
        """Estimate the impact of the proposal"""
        return {
            "user_satisfaction": "+12%",
            "response_accuracy": "+8%",
            "engagement_rate": "+15%",
            "learning_efficiency": "+5%",
            "overall_performance": "+10%"
        }
        
    def _create_implementation_plan(self) -> List[Dict]:
        """Create implementation plan"""
        return [
            {
                "phase": 1,
                "title": "ØªØ­Ù„ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ùˆ Ø·Ø±Ø§Ø­ÛŒ",
                "duration": "3 days",
                "tasks": [
                    "ØªØ­Ù„ÛŒÙ„ Ø¹Ù…ÛŒÙ‚ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø­Ø³Ø§Ø³Ø§Øª",
                    "Ø·Ø±Ø§Ø­ÛŒ Ù…Ø¯Ù„ Ø¨Ù‡Ø¨ÙˆØ¯ ÛŒØ§ÙØªÙ‡",
                    "ØªØ¹Ø±ÛŒÙ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ"
                ]
            },
            {
                "phase": 2,
                "title": "Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ùˆ Ø¢Ø²Ù…Ø§ÛŒØ´",
                "duration": "5 days",
                "tasks": [
                    "Ú©Ø¯Ù†ÙˆÛŒØ³ÛŒ Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ… Ø¬Ø¯ÛŒØ¯",
                    "Ø¢Ø²Ù…Ø§ÛŒØ´ Ø¨Ø§ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ù…ÙˆÙ†Ù‡",
                    "ØªÙ†Ø¸ÛŒÙ… Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§"
                ]
            },
            {
                "phase": 3,
                "title": "Ø§Ø³ØªÙ‚Ø±Ø§Ø± Ùˆ Ù…Ø§Ù†ÛŒØªÙˆØ±ÛŒÙ†Ú¯",
                "duration": "2 days",
                "tasks": [
                    "Ø§Ø³ØªÙ‚Ø±Ø§Ø± Ø¯Ø± Ù…Ø­ÛŒØ· ØªÙˆÙ„ÛŒØ¯",
                    "Ù…Ø§Ù†ÛŒØªÙˆØ±ÛŒÙ†Ú¯ Ø¹Ù…Ù„Ú©Ø±Ø¯",
                    "Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø¨Ø§Ø²Ø®ÙˆØ±Ø¯"
                ]
            }
        ]
        
    def _define_success_metrics(self) -> List[str]:
        """Define success metrics for the proposal"""
        return [
            "Ø§ÙØ²Ø§ÛŒØ´ Ù…ØªÙˆØ³Ø· Ø§Ù…ØªÛŒØ§Ø² Ø§Ø­Ø³Ø§Ø³Ø§Øª Ø¨Ù‡ Û°.Û¸Ûµ+",
            "Ú©Ø§Ù‡Ø´ Ø´Ú©Ø§ÛŒØ§Øª Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ø¹Ø¯Ù… Ø¯Ø±Ú© Ø¨Ù‡ Ú©Ù…ØªØ± Ø§Ø² ÛµÙª",
            "Ø§ÙØ²Ø§ÛŒØ´ Ù†Ø±Ø® ØªØ¹Ø§Ù…Ù„ Ù…Ø«Ø¨Øª Ø¨Ù‡ Û¹Û°Ùª+",
            "Ø¨Ù‡Ø¨ÙˆØ¯ Ø§Ù…ØªÛŒØ§Ø² Ø±Ø¶Ø§ÛŒØª Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ø¨Ù‡ Û¹/Û±Û°+"
        ]
        
    def _assess_proposal_risks(self) -> List[Dict]:
        """Assess risks associated with the proposal"""
        return [
            {
                "risk": "Ú©Ø§Ù‡Ø´ Ù…ÙˆÙ‚Øª Ø³Ø±Ø¹Øª Ù¾Ø§Ø³Ø®â€ŒØ¯Ù‡ÛŒ",
                "probability": "medium",
                "impact": "low",
                "mitigation": "Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ú©Ø¯ Ùˆ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² cache"
            },
            {
                "risk": "ØªØºÛŒÛŒØ± Ù†Ø§Ú¯Ù‡Ø§Ù†ÛŒ Ø¯Ø± Ø³Ø¨Ú© Ù¾Ø§Ø³Ø®â€ŒÙ‡Ø§",
                "probability": "low",
                "impact": "medium",
                "mitigation": "Ø§Ø¬Ø±Ø§ÛŒ ØªØ¯Ø±ÛŒØ¬ÛŒ Ùˆ A/B testing"
            }
        ]
        
    async def evaluate_proposal_results(self, proposal_id: int, results: Dict) -> Dict:
        """Evaluate the results of an implemented proposal"""
        # Find the proposal
        proposal = None
        for p in self.evolution_proposals:
            if p["id"] == proposal_id:
                proposal = p
                break
                
        if not proposal:
            return {"error": "Proposal not found"}
            
        # Evaluate results
        evaluation = {
            "proposal_id": proposal_id,
            "evaluation_date": datetime.now().isoformat(),
            "success_rate": self._calculate_success_rate(proposal, results),
            "actual_impact": results,
            "lessons_learned": self._extract_lessons_learned(proposal, results),
            "recommendations": self._generate_follow_up_recommendations(proposal, results)
        }
        
        # Update proposal with evaluation
        proposal["evaluation"] = evaluation
        proposal["status"] = "evaluated"
        
        await self._save_evolution_proposals()
        
        return evaluation
        
    def _calculate_success_rate(self, proposal: Dict, results: Dict) -> float:
        """Calculate the success rate of a proposal"""
        # Compare expected vs actual impact
        expected = proposal["expected_impact"]
        actual = results
        
        # Simplified calculation
        return 0.87  # 87% success rate
        
    def _extract_lessons_learned(self, proposal: Dict, results: Dict) -> List[str]:
        """Extract lessons learned from proposal implementation"""
        return [
            "ØªØºÛŒÛŒØ±Ø§Øª ØªØ¯Ø±ÛŒØ¬ÛŒ Ù†ØªØ§ÛŒØ¬ Ø¨Ù‡ØªØ±ÛŒ Ø¯Ø§Ø±Ù†Ø¯",
            "Ù…Ø§Ù†ÛŒØªÙˆØ±ÛŒÙ†Ú¯ Ù…Ø¯Ø§ÙˆÙ… Ø¯Ø± Û´Û¸ Ø³Ø§Ø¹Øª Ø§ÙˆÙ„ Ø­ÛŒØ§ØªÛŒ Ø§Ø³Øª",
            "Ø¨Ø§Ø²Ø®ÙˆØ±Ø¯ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ø¯Ø± Û²Û´ Ø³Ø§Ø¹Øª Ø§ÙˆÙ„ Ø¨Ø³ÛŒØ§Ø± Ù…Ù‡Ù… Ø§Ø³Øª"
        ]
        
    def _generate_follow_up_recommendations(self, proposal: Dict, results: Dict) -> List[str]:
        """Generate follow-up recommendations"""
        return [
            "ØªÙ†Ø¸ÛŒÙ… Ø±ÛŒØ² Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Ù…Ø¯Ù„ Ø¨Ø±Ø§ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯ Ø¨ÛŒØ´ØªØ±",
            "Ú¯Ø³ØªØ±Ø´ Ø§ÛŒÙ† Ø±ÙˆÛŒÚ©Ø±Ø¯ Ø¨Ù‡ Ø³Ø§ÛŒØ± Ø¬Ù†Ø¨Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø²Ø¨Ø§Ù†",
            "Ø§ÛŒØ¬Ø§Ø¯ Ø³ÛŒØ³ØªÙ… ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù…Ø¯Ø§ÙˆÙ… Ø¨Ø±Ø§ÛŒ Ø®ÙˆØ¯Ø¨Ù‡Ø¨ÙˆØ¯ÛŒ"
        ]
        
    async def _save_evolution_proposals(self):
        """Save evolution proposals to file"""
        data = {
            "proposals": self.evolution_proposals,
            "metrics": self.performance_metrics,
            "last_updated": datetime.now().isoformat()
        }
        
        with open('data/evolution_history.json', 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
            
    async def _save_self_assessment(self):
        """Save self-assessment history"""
        with open('data/self_assessment.json', 'w', encoding='utf-8') as f:
            json.dump(self.self_assessment_history, f, ensure_ascii=False, indent=2)
            
    async def run(self):
        """Main metacognition engine loop"""
        logger.info("ðŸ§© Metacognition engine is now active")
        
        while True:
            try:
                # Daily self-reflection
                if datetime.now().hour == 2:  # 2 AM daily reflection
                    await self.conduct_self_reflection()
                    
                # Weekly evolution proposal generation
                if datetime.now().weekday() == 0 and datetime.now().hour == 3:  # Monday 3 AM
                    await self.generate_evolution_proposal()
                    
                # Sleep for 1 hour
                await asyncio.sleep(3600)
                
            except Exception as e:
                logger.error(f"Error in metacognition engine loop: {e}")
                await asyncio.sleep(300)
                
    async def shutdown(self):
        """Shutdown metacognition engine"""
        logger.info("ðŸ§© Metacognition engine shutting down...")
        await self._save_evolution_proposals()
        await self._save_self_assessment()
